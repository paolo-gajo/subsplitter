{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# merge srts\n",
    "\n",
    "import time\n",
    "\n",
    "time_string = time.strftime(\"%Y%m%d\")\n",
    "\n",
    "# Set the directory you want to start from\n",
    "root_dir = '/home/pgajo/working/subtitling/subsplitter/data/raw_srts' \n",
    "\n",
    "output_dir = '/home/pgajo/working/subtitling/subsplitter/data/merged_srts'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "def merge_srt_files(root_dir):\n",
    "    # Get a list of all .srt files in the directory\n",
    "    srt_files = glob.glob(os.path.join(root_dir, '*.srt'))\n",
    "\n",
    "    # Sort the files in ascending order (optional)\n",
    "    srt_files.sort()\n",
    "\n",
    "    # Get the name of the directory\n",
    "    dir_name = os.path.basename(output_dir)\n",
    "\n",
    "    # Output file will be named as directory name with '_merged' suffix\n",
    "    output_file = os.path.join(output_dir, f'{dir_name}_merged_{time_string}.srt')\n",
    "\n",
    "    with open(output_file, 'w') as outfile:\n",
    "        # Initialize subtitle index\n",
    "        subtitle_index = 1\n",
    "        for fname in srt_files:\n",
    "            with open(fname) as infile:\n",
    "                for line in infile:\n",
    "                    # Check if line is a subtitle index\n",
    "                    if line.strip().isdigit():\n",
    "                        # Write the new subtitle index and increment it\n",
    "                        outfile.write(str(subtitle_index) + '\\n')\n",
    "                        subtitle_index += 1\n",
    "                    else:\n",
    "                        # Write the line as is\n",
    "                        outfile.write(line)\n",
    "\n",
    "    # count number of \\n\\n\\n in file\n",
    "    with open(output_file, 'r') as infile:\n",
    "        filedata = infile.read()\n",
    "        count = filedata.count('\\n\\n\\n')\n",
    "        print(count)\n",
    "    \n",
    "    # remove triple \\n\n",
    "    with open(output_file, 'r') as infile:\n",
    "        filedata = infile.read()\n",
    "        filedata = filedata.replace('\\n\\n\\n', '\\n')\n",
    "\n",
    "        # count number of \\n\\n\\n in file\n",
    "    with open(output_file, 'r') as infile:\n",
    "        filedata = infile.read()\n",
    "        count = filedata.count('\\n\\n\\n')\n",
    "        print(count)\n",
    "\n",
    "    return output_file\n",
    "\n",
    "output_file = merge_srt_files(root_dir)\n",
    "print(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter subtitles by length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines in /home/pgajo/working/subtitling/subsplitter/data/merged_srts/merged_srts_merged_20231103.srt: 1279002\n",
      "Number of lines longer than 32 characters in /home/pgajo/working/subtitling/subsplitter/data/merged_srts/merged_srts_merged_20231103.srt: 8144\n",
      "Number of lines in /home/pgajo/working/subtitling/subsplitter/data/merged_srts/merged_srts_merged_20231103_32.srt: 437143\n",
      "Number of lines longer than 32 characters in /home/pgajo/working/subtitling/subsplitter/data/merged_srts/merged_srts_merged_20231103_32.srt: 0\n"
     ]
    }
   ],
   "source": [
    "def read_srt_block(file):\n",
    "    number = file.readline().rstrip()\n",
    "    timestamp = file.readline().rstrip()\n",
    "    lines = []\n",
    "    while True:\n",
    "        line = file.readline().rstrip()\n",
    "        if line == '':\n",
    "            break\n",
    "        lines.append(line)\n",
    "    return number, timestamp, lines\n",
    "\n",
    "def write_srt_block(file, number, timestamp, lines):\n",
    "    file.write(f\"{number}\\n\")\n",
    "    file.write(f\"{timestamp}\\n\")\n",
    "    for line in lines:\n",
    "        file.write(f\"{line}\\n\")\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "def remove_formatting_tags(line):\n",
    "    line_without_tags = re.sub('<[^>]*>', '', line)\n",
    "    line_without_double_spaces = re.sub(' +', ' ', line_without_tags)\n",
    "    return line_without_double_spaces\n",
    "\n",
    "# output_file = '/home/pgajo/working/subtitling/subsplitter/data/merged_srt_singlefile/merged_srt_singlefile_merged.srt'\n",
    "\n",
    "# define filtered output file name\n",
    "output_file_merged = output_file[:-4] + \"_32.srt\"\n",
    "\n",
    "with open(output_file, \"r\", encoding='utf8') as unfiltered_file, open(output_file_merged, \"w\", encoding='utf8') as filtered_file:\n",
    "    while True:\n",
    "        number, timestamp, lines = read_srt_block(unfiltered_file)\n",
    "        if number == '':\n",
    "            break\n",
    "        if all(len(remove_formatting_tags(line.strip())) <= 32 for line in lines):\n",
    "            write_srt_block(filtered_file, number, timestamp, lines)\n",
    "\n",
    "# check number of lines that are longer than 32 characters in output_file and output_file_merged\n",
    "\n",
    "with open(output_file, \"r\", encoding='utf8') as f:\n",
    "    lines = f.readlines()\n",
    "    print(f\"Number of lines in {output_file}: {len(lines)}\")\n",
    "    print(f\"Number of lines longer than 32 characters in {output_file}: {len([line for line in lines if len(remove_formatting_tags(line.strip())) > 32])}\")\n",
    "\n",
    "with open(output_file_merged, \"r\", encoding='utf8') as g:\n",
    "    lines = g.readlines()\n",
    "    print(f\"Number of lines in {output_file_merged}: {len(lines)}\")\n",
    "    print(f\"Number of lines longer than 32 characters in {output_file_merged}: {len([line for line in lines if len(remove_formatting_tags(line.strip())) > 32])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare subtitles as a training dataset for T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract subtitle lines and join them with \\n\n",
    "\n",
    "with open(output_file_merged, 'r', encoding='utf8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "def extract_subtitles(text):\n",
    "    blocks = text.strip().split('\\n\\n')\n",
    "    subtitles = []\n",
    "\n",
    "    for block in blocks:\n",
    "        # print('block', block)\n",
    "        lines = block.split('\\n')[1:]\n",
    "        # print('lines', lines)\n",
    "        subtitle_line = '|'.join([line for line in lines if not '-->' in line]) # | is used to split lines within the same subtitle\n",
    "        subtitle_line = re.sub('♪', '#', subtitle_line)\n",
    "        # print('subtitle_line', subtitle_line)\n",
    "        if subtitle_line:\n",
    "            if subtitles and not subtitles[-1][-1] in {'.', '!', '?', ']', '[', '♪', '<', '>'}:\n",
    "                # print('check')\n",
    "                subtitles[-1] += '•' + subtitle_line # • is used to separate subtitles\n",
    "            else:\n",
    "                subtitles.append(subtitle_line)\n",
    "    return subtitles\n",
    "\n",
    "subtitle_lines_w_lb_newlines=extract_subtitles(content)\n",
    "print(len(subtitle_lines_w_lb_newlines))\n",
    "subtitle_lines_w_lb_newlines[:10]\n",
    "\n",
    "# create a new list of subtitled without |, i.e., a list of unsplit subtitles\n",
    "\n",
    "def remove_lb(sub_list):\n",
    "    sub_list_no_lb = []\n",
    "    for sub in sub_list:\n",
    "        sub_no_lb=re.sub('\\|', ' ', sub)\n",
    "        sub_no_lb=re.sub('\\•', ' ', sub_no_lb)\n",
    "        sub_list_no_lb.append(sub_no_lb)\n",
    "    return sub_list_no_lb\n",
    "\n",
    "subtitle_lines_no_lb=remove_lb(subtitle_lines_w_lb_newlines)\n",
    "\n",
    "for i,line in enumerate(subtitle_lines_no_lb[0:10]):\n",
    "    print(i,line)\n",
    "\n",
    "# convert the two lists into a dataframe\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'NO_LB': subtitle_lines_no_lb,\n",
    "    'LB': subtitle_lines_w_lb_newlines,\n",
    "    })\n",
    "display(df)\n",
    "\n",
    "df['max_len'] = 32\n",
    "df['line_length'] = df['NO_LB'].apply(lambda x: len(x))\n",
    "df['exceeds_max_len'] = df['line_length'] > df['max_len']\n",
    "df['exceeds_max_len'] = df['exceeds_max_len'].astype(int)\n",
    "display(df)\n",
    "# save the dataframe\n",
    "output_filename = output_file_merged[:-4] + '_prepped.csv'\n",
    "df.to_csv(output_filename, index=False)\n",
    "print('df saved to', output_filename)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pgajo-Fz_qUQZq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
